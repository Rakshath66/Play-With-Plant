Here's your `README.md` for the **ğŸŒ± AI Mood Plant** project â€” following the same format and tone as your CLIP project:

---

# ğŸŒ± AI Mood Plant â€” Emotion-Aware Interactive App

A playful and emotionally intelligent **plant companion** that reacts to your facial expression. Powered by facial emotion recognition and Streamlit UI â€” just click, capture, and watch the plant react in real time!

> âœ… Built with: `FER Transformer`, `Streamlit`, `PIL`, `PyTorch`, `Transformers`

![GitHub Repo stars](https://img.shields.io/github/stars/rakshath66/play-with-plant?style=social)
![GitHub forks](https://img.shields.io/github/forks/rakshath66/play-with-plant?style=social)
![MIT License](https://img.shieHlds.io/github/license/rakshath66/play-with-plant)

---

## ğŸŒ¿ Preview

![image](images/ui.png)

---

## ğŸ§  Features

* ğŸ“¸ Live camera input to **capture your emotion**
* ğŸ§  Classifies face into **Happy, Neutral, or Sad**
* ğŸŒ± Displays a plant that **reflects your mood**
* ğŸª Real-time emotion detection with a simple UI
* ğŸ¨ Clean and engaging layout for kids and adults

---

## ğŸš€ Getting Started

### ğŸ”§ Prerequisites

* Python 3.9 or above (recommended)
* Webcam-enabled device

---

### ğŸ–¥ï¸ Local Installation

```bash
# 1. Clone the repository
git clone https://github.com/rakshath66/play-with-plant.git
cd play-with-plant

# 2. (Optional) Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows use: venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Run the app
streamlit run app.py
```

---

## ğŸ—‚ï¸ Project Structure

```
play-with-plant/
â”œâ”€â”€ app.py                  # Main Streamlit app
â”œâ”€â”€ plants/                 # Mood-based plant images (happy.jpg, sad.jpg, etc.)
â”œâ”€â”€ images/                 # UI preview image (optional)
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ README.md               # This file
```

---

## ğŸ“š Technology Used

* ğŸ¤— [ViT Face Expression Model](https://huggingface.co/trpakov/vit-face-expression)
* ğŸ§  Hugging Face Transformers
* ğŸ“· Streamlitâ€™s built-in camera input
* ğŸ§® PyTorch for inference
* ğŸ–¼ï¸ PIL for image processing

---

## ğŸŒˆ Example Use Cases

* Kids' emotional awareness games
* Mood-based digital art or plants
* Emotional journaling apps
* Mental health awareness demos

---

## ğŸ” No API Keys Needed

This app uses Hugging Face-hosted models **for free**.
If you hit limits, just run:

```bash
huggingface-cli login
```

---

## â­ Contribute

### ğŸ›  Steps to contribute:

1. Fork the repo
2. Create a branch: `git checkout -b my-feature`
3. Make changes and commit: `git commit -m "Add: feature"`
4. Push your branch: `git push origin my-feature`
5. Open a pull request âœ…

> Clean and fun contributions welcome!

---

## ğŸ“ƒ License

MIT License Â© [Rakshath U Shetty](https://github.com/rakshath66)

---

## ğŸ›£ï¸ Roadmap

### âœ… Phase 1: Launch

* Core emotion-to-plant mapping
* Camera input + live mood detection
* Neutral â†’ Happy â†’ Sad mapping

### ğŸ”œ Phase 2: Next Features

* ğŸï¸ Add GIF-style animation for plants
* ğŸ§  Mood journal with time logs
* ğŸŒ Share plant mood on social media
* ğŸ—£ï¸ Voice feedback based on emotion

---

### ğŸ‘¨â€ğŸ’» Built by [Rakshath U Shetty](https://www.linkedin.com/in/rakshathushetty/)

---

Let me know if you'd like badges for Streamlit Cloud or Hugging Face Spaces added!
